{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "* You're probably aware of some parametric prediction methods, e.g., linear regression.  \n",
    "* Let's study a non-parametric prediction method. \n",
    "* The goal of this method: classify something into one of a discrete number of types. \n",
    "* This is also known as 'supervised learning'. \n",
    "\n",
    "# Scikit-Learn\n",
    "\n",
    "* Scikit-Learn is a major machine learning library that includes many reference data sets. \n",
    "* Initial release: June 2007, predates `pandas` but not by much! (Scikit-Learn and `pandas` solved different set of problems so they could simply coexisted for a long time)\n",
    "* It has its own formats. \n",
    "* It's important to know how to translate to other formats to accomplish tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" style=\"padding-left:10px; height: 24%; width: 24%;\" src=\"figures/iris_with_labels.jpg\">\n",
    "\n",
    "# The Iris Dataset\n",
    "\n",
    "* There is one dataset that is so well-known that it bears mentioning in any context. \n",
    "* The *iris dataset* consists of a multidimensional array of iris characteristics used in determining species. \n",
    "* Let's explore this dataset and see if we can understand it. \n",
    "* More information on the iris dataset is available at the [Scikit-Learn website](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html).\n",
    "* Scikit-Learn also provides a [Jupyter notebook](plot_iris_dataset.ipynb) included here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': '/opt/tljh/user/lib/python3.6/site-packages/sklearn/datasets/data/iris.csv'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "iris\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a special-purpose format. \n",
    "* A class\n",
    "* Implemented as a dictionary. \n",
    "* Intended for testing machine-learning algorithms. \n",
    "* With fields that make sense for that task.\n",
    "* Most entries are arrays in `numpy` format. \n",
    "\n",
    "Let's find out a bit about it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important fields in the iris dataset\n",
    "* `iris.data`: a set of feature vectors describing different plants. \n",
    "* `iris.target`: the kind of plant\n",
    "* `iris.feature_names`: the names of columns\n",
    "* `iris.target_names`: the English names of the kinds. \n",
    "\n",
    "# The classification problem\n",
    "* Given what we know about a thing (`iris.data`) \n",
    "* What species is it (`iris.target`)? \n",
    "\n",
    "# How we approach classification: \n",
    "* Take all data into account. \n",
    "* Think of the data as a function from `data` to `target`.\n",
    "* Approximate that function. \n",
    "\n",
    "# Then, if there is a new kind of iris, \n",
    "* Use the function to predict what species it is. \n",
    "\n",
    "# Let's run the demo provided by scikit-learn: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.9, 1.0, 5.1, 1.8], [3.4, 2.0, 1.1, 4.8]]\n",
      "[1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Declare a KNN classifier of a given complexity. The number of neighbors determines runtime.\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "# create a map between data and target. \n",
    "knn.fit(iris['data'], iris['target'])\n",
    "\n",
    "# Provide data whose class labels are to be predicted\n",
    "X = [\n",
    "    [5.9, 1.0, 5.1, 1.8],\n",
    "    [3.4, 2.0, 1.1, 4.8],\n",
    "]\n",
    "\n",
    "# Prints the data provided\n",
    "print(X)\n",
    "\n",
    "# Store predicted class labels of X\n",
    "prediction = knn.predict(X)\n",
    "\n",
    "# Prints the predicted class labels of X\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This, according to the predictor, they're both species 1 of 0-2. \n",
    "\n",
    "* Writing such a predictor is a complex task that we study in COMP 135. \n",
    "* You can read up on it here: https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm\n",
    "\n",
    "For now, suffice it to say that from enough measurements, one can form a prediction \n",
    "from the instances that have been observed so far. This prediction can be accurate or inaccurate \n",
    "based upon the prediction method. \n",
    "\n",
    "# From whence comes accuracy\n",
    "* You would be right to be suspicious of what I just did. \n",
    "* I didn't tell you anything at all about the prediction method. It is an \"oracle\". \n",
    "* How do we know that this worked? \n",
    "\n",
    "# Cross-validation\n",
    "* Cross-validation is a standard technique in machine learning for testing classifiers. \n",
    "* Separate all feature data into 'training' and 'testing' subsets. \n",
    "* Train on the training subset. \n",
    "* Test on the testing subset. \n",
    "* See if you get the correct answers.\n",
    "\n",
    "# Let's do this. I'll help.\n",
    "* This is a different kind of exercise. \n",
    "* This is a real cross-validation using random data. \n",
    "* There is no one \"correct\" answer. \n",
    "* I can check your answers for sanity but not for correctness. \n",
    "\n",
    "First let's select rows of the data to use as training and testing data. This recipe selects them randomly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "selections = list(range(len(iris.data)))\n",
    "random.shuffle(selections)\n",
    "training_selections = selections[:130]\n",
    "testing_selections = selections[130:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What this does\n",
    "* `random.shuffle` scrambles the numbers between 0 and 149. \n",
    "* `training_selections` is a list of the array offsets for a training set. \n",
    "* `testing_selections` is a list of the array offsets for a testing set. \n",
    "* These are disjoint lists with no elements in common. \n",
    "* These represent a random sampling of the data in the iris database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[66, 104, 51, 111, 113, 123, 141, 108, 71, 74, 70, 115, 48, 129, 12, 4, 106, 11, 84, 121, 46, 56, 9, 118, 34, 79, 142, 134, 53, 145, 78, 147, 13, 132, 10, 57, 125, 47, 37, 31, 65, 63, 23, 131, 58, 24, 26, 60, 92, 32, 33, 52, 83, 88, 91, 117, 128, 30, 39, 44, 8, 97, 28, 122, 67, 110, 85, 27, 102, 130, 146, 94, 41, 42, 103, 105, 136, 76, 50, 149, 139, 36, 140, 68, 100, 40, 62, 20, 17, 59, 0, 86, 29, 133, 135, 116, 112, 18, 72, 5, 124, 35, 143, 54, 69, 43, 109, 16, 19, 99, 73, 77, 107, 75, 96, 3, 25, 61, 64, 55, 138, 98, 144, 6, 95, 114, 89, 15, 126, 93]\n"
     ]
    }
   ],
   "source": [
    "print(training_selections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38, 1, 7, 21, 45, 22, 120, 81, 101, 49, 119, 127, 90, 137, 2, 87, 148, 14, 80, 82]\n"
     ]
    }
   ],
   "source": [
    "print(testing_selections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================\n",
      "Assignment: 04-02-classification\n",
      "OK, version v1.14.15\n",
      "=====================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Don't change this cell; just run it. \n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('04-02-classification.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create an `array` `training_features` that consists of the rows that match `training_selections`. Look up how to do it. Hint: `iris.data` is an `array`. Use row selection for `np.array`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.6, 3. , 4.5, 1.5],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [5.9, 3. , 5.1, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5.1, 3.5, 1.4, 0.2],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [5. , 2.3, 3.3, 1. ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer:\n",
    "training_features = iris.data[training_selections]\n",
    "training_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 2\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = ok.grade('q01')  # check answer for sanity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create an `array` `training_targets` that consists of the targets corresponding to the selected training rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 2, 2, 2, 2, 2, 1, 1, 1, 2, 0, 2, 0, 0, 2, 0, 1, 2, 0, 1,\n",
       "       0, 2, 0, 1, 2, 2, 1, 2, 1, 2, 0, 2, 0, 1, 2, 0, 0, 0, 1, 1, 0, 2,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 2, 2, 0, 0, 0, 0, 1, 0, 2, 1, 2,\n",
       "       1, 0, 2, 2, 2, 1, 0, 0, 2, 2, 2, 1, 1, 2, 2, 0, 2, 1, 2, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 2, 2, 2, 2, 0, 1, 0, 2, 0, 2, 1, 1, 0, 2, 0, 0, 1,\n",
       "       1, 1, 2, 1, 1, 0, 0, 1, 1, 1, 2, 1, 2, 0, 1, 2, 1, 0, 2, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer\n",
    "training_targets = iris.target[training_selections]\n",
    "training_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 2\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = ok.grade('q02')  # check answer for sanity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Using the pattern above, train a kNN on the training data. Start with a new one `knn2` and just train on this. Hint: You need the data from parts 1 and 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=6, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer: \n",
    "# Declare a KNN classifier of a given complexity. The number of neighbors determines runtime.\n",
    "import numpy as np\n",
    "\n",
    "knn2 = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "# create a map between data and target. \n",
    "knn2.fit(training_features, training_targets)\n",
    "knn2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Put the test data into an `array` `testing_features`, repeating what you did for training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.4, 3. , 1.3, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.8, 2.7, 3.9, 1.2]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer: \n",
    "testing_features = iris.data[testing_selections]\n",
    "testing_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 2\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = ok.grade('q04')  # check answer for sanity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Run the predictor as above, but on the array `testing_features`. Put the result into `test_results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 2, 1, 2, 0, 1, 2, 1, 2, 0, 1, 2, 0, 1, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer: \n",
    "test_results = knn.predict(testing_features)\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 2\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = ok.grade('q05')  # check answer for sanity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Compute the expected outcomes and put them into the `array` `expected_results`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 2, 1, 2, 0, 2, 2, 1, 2, 0, 1, 2, 0, 1, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer: \n",
    "expected_results = iris.target[testing_selections]\n",
    "expected_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 2\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = ok.grade('q06')  # check answer for sanity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Count the number of identical answers between test_results and expected results and place the result into `correct_answers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer: \n",
    "correct_answers = (test_results == expected_results).sum()\n",
    "correct_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An afterword on cross-validation\n",
    "* If you got a perfect result, you're lucky. \n",
    "* Classification algorithms aren't perfect. \n",
    "* You can run it again to get an imperfect result. \n",
    "* Running the cross-validation multiple times gives one an idea of how accurate the classifier will be. \n",
    "* There are no \"correct\" answers to this. You just ran a random trial. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When you are done with this notebook, \n",
    "\n",
    "* Save and checkpoint. \n",
    "* Ensure that the name of this file is precisely `04-02-classification.ipynb`. \n",
    "* Save and checkpoint the notebook. \n",
    "\n",
    "\n",
    "* If your Jupyter installation can download the notebook as a PDF,\n",
    "    * (File >> Download as >> PDF via LaTeX (.pdf)), \n",
    "    * Rename the downloaded file to `<loginid>-04-02-classification.pdf`. In other words, my filename would be `jsingh11-04-02-classification.pdf`.\n",
    "    * Submit the file `<loginid>-04-02-classification.pdf` to Canvas.\n",
    "* Otherwise \n",
    "    * (File >> Download as >> Notebook (.ipynb)). In other words, my filename would be `jsingh11-04-02-classification.ipynb`.\n",
    "    * Rename the downloaded file to `<loginid>-04-02-classification.ipynb`,\n",
    "    * Submit the file `<loginid>-04-02-classification.ipynb` to Canvas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
